package mapreduce

import (
	"bufio"
	"encoding/json"
	"fmt"
	"hash/fnv"
	"log"
	"os"
	"sort"
	"strconv"
)

const OutputPre = "/tmp/824-proj1-"

// A simple mapreduce library with a sequential implementation.
//
// The application provides an input file f, a Map and Reduce function,
// and the number of nMap and nReduce tasks.
//
// Split() splits the file f in nMap input files:
//    f-0, f-1, ..., f-<nMap-1>
// one for each Map job.
//
// DoMap() runs Map on each map file and produces nReduce files for each
// map file.  After Map job N runs, there will be nReduce files, numbered
//     f-N-0, f-N-1, ..., f-N-<nReduce>
//
// Thus, after all map jobs are done, there will be nMap x nReduce files:
//    f-0-0, ..., f-0-0, f-0-<nReduce-1>, ...,
//    f-<nMap-1>-0, ... f-<nMap-1>-<nReduce-1>.
//
// DoReduce() collects the <nMap> files from generated by each Map job
// for that reduce job (f-*-<reduce>), and runs Reduce on those files.
//
// This produces <nReduce> result files, which Merge() merges into a
// single output.

// Debugging
const debug = 0

func dPrintf(format string, a ...interface{}) (n int, err error) {
	if debug > 0 {
		n, err = fmt.Printf(format, a...)
	}
	return
}

func errCheck(err error, v ...any) {
	if err != nil {
		log.Fatal("MR:", v, err)
	}
}

// Map and Reduce deal with <key, value> pairs
// Each API client must write a map function to produce these
type KeyValue struct {
	Key   string
	Value string
}

// A single MapReduce task
type MapReduce struct {
	FileName  string // The file to be processed
	NMap      int    // Number of map jobs
	NReduce   int    // Number of reduce jobs
}

// Name of the file that is the input for map job <MapJob>
func mapName(fileName string, MapJob int) string {
	return OutputPre + strconv.Itoa(os.Getuid()) + 
		"/mrtmp." + fileName + "-" + strconv.Itoa(MapJob)
}

// Open a map file for writing
func mapFile(fileName string, job int) (*os.File, *bufio.Writer) {
	outfile, err := os.Create(mapName(fileName, job))
	errCheck(err, "mapFile")
	writer := bufio.NewWriter(outfile)

	return outfile, writer
}

func reduceName(fileName string, MapJob int, ReduceJob int) string {
	return mapName(fileName, MapJob) + "-" + strconv.Itoa(ReduceJob)
}

func mergeName(fileName string, ReduceJob int) string {
	return OutputPre + strconv.Itoa(os.Getuid()) + 
		"/mrtmp." + fileName + "-res-" + strconv.Itoa(ReduceJob)
}

func iHash(s string) uint32 {
	h := fnv.New32a()
	h.Write([]byte(s))
	return h.Sum32()
}

// Split bytes of input file into nMap splits, but split only on white space
func (mr MapReduce) Split() {
	dPrintf("MR: split %s\n", mr.FileName)

	// Open the file to be processed
	infile, err := os.Open(mr.FileName)
	errCheck(err, "split")
	defer infile.Close()

	// Compute the expected number of characters per chunk
	stat, err := infile.Stat()
	errCheck(err, "split")
	size := stat.Size()
	nChunk := (size / int64(mr.NMap)) + 1

	// Set up state for creating map-stage input files
	// This depends on the file being large relative to
	// the number of map jobs, because we only break on
	// line boundaries.
	//
	// Invariants:
	//     m is the current map-job file being created [0..N-1]
	//     outfile is the map-job file for job m
	//     writer spools to the current outfile
	//     i counts the number of characters written so far
	//       across all chunks, such that i <= (m+1) * nChunk

	// Set up state for initial iteration
	m := 0
	outfile, writer := mapFile(mr.FileName, m)
	i := 0

	// process input file
	scanner := bufio.NewScanner(infile)
	for scanner.Scan() {
		// Check invariant on i, advance if necessary
		if int64(i) > nChunk*int64(m+1) {
			writer.Flush()
			outfile.Close()
			m += 1
			outfile, writer = mapFile(mr.FileName, m)
		}
		line := scanner.Text() + "\n"
		writer.WriteString(line)
		i += len(line)
	}
	// I chose not to use defer for these, because they also
	// happen in the loop body. This is arguably bad style
	writer.Flush()
	outfile.Close()
}

// Read split for job, call Map for that split, and create nreduce
// partitions.
func DoMap(JobNumber int, fileName string,
	nReduce int, Map func(string) []KeyValue) {

	// Open the chunk being mapped in this job
	name := mapName(fileName, JobNumber)
	file, err := os.Open(name)
	errCheck(err, "DoMap")
	defer file.Close()

	// How big is it?
	fi, err := file.Stat()
	errCheck(err, "DoMap")
	size := fi.Size()

	// Log it
	dPrintf("DoMap: read split %s %d\n", name, size)

	// Read into a buffer
	b := make([]byte, size)
	_, err = file.Read(b)
	errCheck(err, "DoMap")

	// Map the chunk
	res := Map(string(b))

	// Scatter the Map results to nReduce files for the reducers
	// Each reducer will eventually have nMap input files

	// Use json encoding to handle marshaling/unmarshaling
	encoders := make([]*json.Encoder, nReduce)

	// Create one encoder for each of the nReduce files
	for i := 0; i < nReduce; i++ {
		file, err := os.Create(reduceName(fileName, JobNumber, i))
		defer file.Close()
		errCheck(err, "DoMap: create")
		encoders[i] = json.NewEncoder(file)
	}

	// Walk the keys, scattering them based on iHash
	for _, kv := range res {
		dest := iHash(kv.Key) % uint32(nReduce)
		err := encoders[dest].Encode(&kv)
		errCheck(err, "DoMap: marshal")
	}
}

// Read map outputs for this reduce job, sort them by key, then call
// reduce for each key

func DoReduce(rJob int, fileName string, nMap int,
	Reduce func(string, []string) string) {

	// Key followed by the list of mapped values
	kvs := make(map[string][]string)

	// Read the input to this reduce job from each map job
	for i := 0; i < nMap; i++ {

		// Get values produced by Map job i
		name := reduceName(fileName, i, rJob)
		dPrintf("DoReduce: read %s\n", name)
		file, err := os.Open(name)
		errCheck(err, "DoReduce")

		// Parse those values into the key-value store
		decoder := json.NewDecoder(file)
		for {
			var kv KeyValue
			err = decoder.Decode(&kv)
			if err != nil {
				// We produced it; only error is end-of-file
				break
			}

			// Instantiate this key if we've never seen it before
			// with an empty list.
			_, ok := kvs[kv.Key]
			if !ok {
				kvs[kv.Key] = make([]string, 0)
			}

			// Add this value to the value-list
			// We are trusting the golang runtime to
			// extend the slice's underlying array sensibly
			kvs[kv.Key] = append(kvs[kv.Key], kv.Value)

		}
		// We don't use defer for this, because we don't need all
		// files to be open to the end of the function. Intsead
		// we close each file at the end of its iteration.
		// This is arguably bad style.
		file.Close()
	}

	// Sort the keys to guarantee Reducer produces output in
	// sorted-order, simplifying the merge later.
	var keys []string
	for k := range kvs { // Note: range over a map is random-order
		keys = append(keys, k)
	}
	sort.Strings(keys)

	// Call reduce for each key in turn, placing the output
	// in a merge file
	mName := mergeName(fileName, rJob)
	file, err := os.Create(mName)
	errCheck(err, "DoReduce: Create")
	defer file.Close()

	enc := json.NewEncoder(file)
	for _, k := range keys { // Note: range over a slice is in-order
		res := Reduce(k, kvs[k])
		enc.Encode(KeyValue{k, res})
	}
}

// Merge strategy:
// Create a decoder for each of the |Reduce| reduce output files
// At each step, determine the smallest key, and emit it, then replace it
//
// This may exhaust reduce outputs at different times, so keep track of
// which ones still have at least one key to consider.
//
// When none of them do, we are done
//
// This function is too long--break it into two

func (mr MapReduce) Merge() {
	dPrintf("Merge phase\n")

	// Set up the initial conditions
	hasKey := make([]bool, mr.NReduce) // defaults to false
	keys := make([]KeyValue, mr.NReduce)
	decoders := make([]*json.Decoder, mr.NReduce)
	remaining := 0

	// Prime the pump for each mergefile
	for i := 0; i < mr.NReduce; i++ {
		// Open the file
		mName := mergeName(mr.FileName, i)
		file, err := os.Open(mName)
		errCheck(err, "Merge: open")
		defer file.Close()

		// Get the first key (or not)
		decoders[i] = json.NewDecoder(file)
		err = decoders[i].Decode(&keys[i])
		if err == nil {
			hasKey[i] = true
			remaining += 1
		}
	}

	// Open the output file and attach a writer
	outfile, err := os.Create(OutputPre + strconv.Itoa(os.Getuid()) + 
		"/mrtmp." + mr.FileName)
	errCheck(err, "Merge: output create")
	defer outfile.Close()
	w := bufio.NewWriter(outfile)
	defer w.Flush()

	// While there are keys remaining, write the "smallest" one
	var smallest int
	for remaining > 0 {
		// Make the first valid key the candidate for smallest
		// remaining > 0 implies there must be at least one
		// I arguably should include an assert here
		for smallest = 0; smallest < mr.NReduce; smallest++ {
			if hasKey[smallest] {
				break
			}
		}

		// Find the smallest valid key
		for i := smallest + 1; i < mr.NReduce; i++ {
			if hasKey[i] && keys[i].Key < keys[smallest].Key {
				smallest = i
			}
		}

		// Write out that key
		fmt.Fprintf(w, "%s: %s\n",
			keys[smallest].Key,
			keys[smallest].Value)

		// Consume that key
		err = decoders[smallest].Decode(&keys[smallest])
		if err != nil {
			hasKey[smallest] = false
			remaining -= 1
		}
	}
}

// Run a sequential mapreduce task
func DoSequential(nMap int, nReduce int, file string,
	Map func(string) []KeyValue,
	Reduce func(string, []string) string) {

	mr := MapReduce{file, nMap, nReduce}

	mr.Split()
	for i := 0; i < mr.NMap; i++ {
		DoMap(i, mr.FileName, mr.NReduce, Map)
	}
	for i := 0; i < mr.NReduce; i++ {
		DoReduce(i, mr.FileName, mr.NMap, Reduce)
	}
	mr.Merge()
}
